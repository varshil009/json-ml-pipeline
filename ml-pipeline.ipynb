{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11f4d8df-7a7e-4d9b-86e8-e06646bbebc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from striprtf.striprtf import rtf_to_text\n",
    "import json\n",
    "\n",
    "with open(r\"C:\\Users\\91962\\Downloads\\DS_Assignment - internship\\Screening Test - DS\\algoparams_from_ui.json.rtf\", \"r\", encoding=\"utf-8\") as file:\n",
    "    rtf_content = file.read()\n",
    "    \n",
    "text = rtf_to_text(rtf_content)\n",
    "dic = json.loads(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96f09591-cfc2-4e9e-b762-6761dd18f25c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'session_name': 'test',\n",
       " 'session_description': 'test',\n",
       " 'design_state_data': {'session_info': {'project_id': '1',\n",
       "   'experiment_id': 'kkkk-11',\n",
       "   'dataset': 'iris_modified.csv',\n",
       "   'session_name': 'test',\n",
       "   'session_description': 'test'},\n",
       "  'target': {'prediction_type': 'Regression',\n",
       "   'target': 'petal_width',\n",
       "   'type': 'regression',\n",
       "   'partitioning': True},\n",
       "  'train': {'policy': 'Split the dataset',\n",
       "   'time_variable': 'sepal_length',\n",
       "   'sampling_method': 'No sampling(whole data)',\n",
       "   'split': 'Randomly',\n",
       "   'k_fold': False,\n",
       "   'train_ratio': 0.7,\n",
       "   'random_seed': 0},\n",
       "  'metrics': {'optomize_model_hyperparameters_for': 'AUC',\n",
       "   'optimize_threshold_for': 'F1 Score',\n",
       "   'compute_lift_at': 0,\n",
       "   'cost_matrix_gain_for_true_prediction_true_result': 1,\n",
       "   'cost_matrix_gain_for_true_prediction_false_result': 0,\n",
       "   'cost_matrix_gain_for_false_prediction_true_result': 0,\n",
       "   'cost_matrix_gain_for_false_prediction_false_result': 0},\n",
       "  'feature_handling': {'sepal_length': {'feature_name': 'sepal_length',\n",
       "    'is_selected': True,\n",
       "    'feature_variable_type': 'numerical',\n",
       "    'feature_details': {'numerical_handling': 'Keep as regular numerical feature',\n",
       "     'rescaling': 'No rescaling',\n",
       "     'make_derived_feats': False,\n",
       "     'missing_values': 'Impute',\n",
       "     'impute_with': 'Average of values',\n",
       "     'impute_value': 0}},\n",
       "   'sepal_width': {'feature_name': 'sepal_width',\n",
       "    'is_selected': True,\n",
       "    'feature_variable_type': 'numerical',\n",
       "    'feature_details': {'numerical_handling': 'Keep as regular numerical feature',\n",
       "     'rescaling': 'No rescaling',\n",
       "     'make_derived_feats': False,\n",
       "     'missing_values': 'Impute',\n",
       "     'impute_with': 'custom',\n",
       "     'impute_value': -1}},\n",
       "   'petal_length': {'feature_name': 'petal_length',\n",
       "    'is_selected': True,\n",
       "    'feature_variable_type': 'numerical',\n",
       "    'feature_details': {'numerical_handling': 'Keep as regular numerical feature',\n",
       "     'rescaling': 'No rescaling',\n",
       "     'make_derived_feats': False,\n",
       "     'missing_values': 'Impute',\n",
       "     'impute_with': 'Average of values',\n",
       "     'impute_value': 0}},\n",
       "   'petal_width': {'feature_name': 'petal_width',\n",
       "    'is_selected': True,\n",
       "    'feature_variable_type': 'numerical',\n",
       "    'feature_details': {'numerical_handling': 'Keep as regular numerical feature',\n",
       "     'rescaling': 'No rescaling',\n",
       "     'make_derived_feats': False,\n",
       "     'missing_values': 'Impute',\n",
       "     'impute_with': 'custom',\n",
       "     'impute_value': -2}},\n",
       "   'species': {'feature_name': 'species',\n",
       "    'is_selected': True,\n",
       "    'feature_variable_type': 'text',\n",
       "    'feature_details': {'text_handling': 'Tokenize and hash',\n",
       "     'hash_columns': 10}}},\n",
       "  'feature_generation': {'linear_interactions': [['petal_length',\n",
       "     'sepal_width']],\n",
       "   'linear_scalar_type': 'robust',\n",
       "   'polynomial_interactions': ['petal_length/sepal_width',\n",
       "    'petal_width/species'],\n",
       "   'explicit_pairwise_interactions': ['sepal_width/sepal_length',\n",
       "    'petal_width/sepal_length']},\n",
       "  'feature_reduction': {'feature_reduction_method': 'Correlation with target',\n",
       "   'Correlation with target': {'is_selected': True, 'num_features_to_keep': 5},\n",
       "   'Tree-based': {'is_selected': False,\n",
       "    'num_features_to_keep': 0,\n",
       "    'depth_of_trees': 0,\n",
       "    'num_of_trees': 0},\n",
       "   'Principal Component Analysis': {'is_selected': False,\n",
       "    'num_features_to_keep': 0}},\n",
       "  'hyperparameters': {'stratergy': 'Grid Search',\n",
       "   'shuffle_grid': True,\n",
       "   'random_state': 1,\n",
       "   'max_iterations': 2,\n",
       "   'max_search_time': 3,\n",
       "   'parallelism': 5,\n",
       "   'cross_validation_stratergy': 'Time-based K-fold(with overlap)',\n",
       "   'num_of_folds': 6,\n",
       "   'split_ratio': 0,\n",
       "   'stratified': True},\n",
       "  'weighting_stratergy': {'weighting_stratergy_method': 'Sample weights',\n",
       "   'weighting_stratergy_weight_variable': 'petal_length'},\n",
       "  'probability_calibration': {'probability_calibration_method': 'Sigmoid - Platt Scaling'},\n",
       "  'algorithms': {'RandomForestClassifier': {'model_name': 'Random Forest Classifier',\n",
       "    'is_selected': False,\n",
       "    'min_trees': 10,\n",
       "    'max_trees': 30,\n",
       "    'feature_sampling_statergy': 'Default',\n",
       "    'min_depth': 20,\n",
       "    'max_depth': 30,\n",
       "    'min_samples_per_leaf_min_value': 5,\n",
       "    'min_samples_per_leaf_max_value': 50,\n",
       "    'parallelism': 0},\n",
       "   'RandomForestRegressor': {'model_name': 'Random Forest Regressor',\n",
       "    'is_selected': True,\n",
       "    'min_trees': 10,\n",
       "    'max_trees': 20,\n",
       "    'feature_sampling_statergy': 'Default',\n",
       "    'min_depth': 20,\n",
       "    'max_depth': 25,\n",
       "    'min_samples_per_leaf_min_value': 5,\n",
       "    'min_samples_per_leaf_max_value': 10,\n",
       "    'parallelism': 0},\n",
       "   'GBTClassifier': {'model_name': 'Gradient Boosted Trees',\n",
       "    'is_selected': False,\n",
       "    'num_of_BoostingStages': [67, 89],\n",
       "    'feature_sampling_statergy': 'Fixed number',\n",
       "    'learningRate': [],\n",
       "    'use_deviance': True,\n",
       "    'use_exponential': False,\n",
       "    'fixed_number': 22,\n",
       "    'min_subsample': 1,\n",
       "    'max_subsample': 2,\n",
       "    'min_stepsize': 0.1,\n",
       "    'max_stepsize': 0.5,\n",
       "    'min_iter': 20,\n",
       "    'max_iter': 40,\n",
       "    'min_depth': 5,\n",
       "    'max_depth': 7},\n",
       "   'GBTRegressor': {'model_name': 'Gradient Boosted Trees',\n",
       "    'is_selected': False,\n",
       "    'num_of_BoostingStages': [67, 89],\n",
       "    'feature_sampling_statergy': 'Fixed number',\n",
       "    'use_deviance': True,\n",
       "    'use_exponential': False,\n",
       "    'fixed_number': 22,\n",
       "    'min_subsample': 1,\n",
       "    'max_subsample': 2,\n",
       "    'min_stepsize': 0.1,\n",
       "    'max_stepsize': 0.5,\n",
       "    'min_iter': 20,\n",
       "    'max_iter': 40,\n",
       "    'min_depth': 5,\n",
       "    'max_depth': 7},\n",
       "   'LinearRegression': {'model_name': 'LinearRegression',\n",
       "    'is_selected': False,\n",
       "    'parallelism': 2,\n",
       "    'min_iter': 30,\n",
       "    'max_iter': 50,\n",
       "    'min_regparam': 0.5,\n",
       "    'max_regparam': 0.8,\n",
       "    'min_elasticnet': 0.5,\n",
       "    'max_elasticnet': 0.8},\n",
       "   'LogisticRegression': {'model_name': 'LogisticRegression',\n",
       "    'is_selected': False,\n",
       "    'parallelism': 2,\n",
       "    'min_iter': 30,\n",
       "    'max_iter': 50,\n",
       "    'min_regparam': 0.5,\n",
       "    'max_regparam': 0.8,\n",
       "    'min_elasticnet': 0.5,\n",
       "    'max_elasticnet': 0.8},\n",
       "   'RidgeRegression': {'model_name': 'RidgeRegression',\n",
       "    'is_selected': False,\n",
       "    'regularization_term': 'Specify values to test',\n",
       "    'min_iter': 30,\n",
       "    'max_iter': 50,\n",
       "    'min_regparam': 0.5,\n",
       "    'max_regparam': 0.8},\n",
       "   'LassoRegression': {'model_name': 'Lasso Regression',\n",
       "    'is_selected': False,\n",
       "    'regularization_term': 'Specify values to test',\n",
       "    'min_iter': 30,\n",
       "    'max_iter': 50,\n",
       "    'min_regparam': 0.5,\n",
       "    'max_regparam': 0.8},\n",
       "   'ElasticNetRegression': {'model_name': 'Lasso Regression',\n",
       "    'is_selected': False,\n",
       "    'regularization_term': 'Specify values to test',\n",
       "    'min_iter': 30,\n",
       "    'max_iter': 50,\n",
       "    'min_regparam': 0.5,\n",
       "    'max_regparam': 0.8,\n",
       "    'min_elasticnet': 0.5,\n",
       "    'max_elasticnet': 0.8},\n",
       "   'xg_boost': {'model_name': 'XG Boost',\n",
       "    'is_selected': False,\n",
       "    'use_gradient_boosted_tree': True,\n",
       "    'dart': True,\n",
       "    'tree_method': '',\n",
       "    'random_state': 0,\n",
       "    'max_num_of_trees': 0,\n",
       "    'early_stopping': True,\n",
       "    'early_stopping_rounds': 2,\n",
       "    'max_depth_of_tree': [56, 89],\n",
       "    'learningRate': [89, 76],\n",
       "    'l1_regularization': [77],\n",
       "    'l2_regularization': [78],\n",
       "    'gamma': [68],\n",
       "    'min_child_weight': [67],\n",
       "    'sub_sample': [67],\n",
       "    'col_sample_by_tree': [67],\n",
       "    'replace_missing_values': False,\n",
       "    'parallelism': 0},\n",
       "   'DecisionTreeRegressor': {'model_name': 'Decision Tree',\n",
       "    'is_selected': False,\n",
       "    'min_depth': 4,\n",
       "    'max_depth': 7,\n",
       "    'use_gini': False,\n",
       "    'use_entropy': True,\n",
       "    'min_samples_per_leaf': [12, 6],\n",
       "    'use_best': True,\n",
       "    'use_random': True},\n",
       "   'DecisionTreeClassifier': {'model_name': 'Decision Tree',\n",
       "    'is_selected': False,\n",
       "    'min_depth': 4,\n",
       "    'max_depth': 7,\n",
       "    'use_gini': False,\n",
       "    'use_entropy': True,\n",
       "    'min_samples_per_leaf': [12, 6],\n",
       "    'use_best': True,\n",
       "    'use_random': True},\n",
       "   'SVM': {'model_name': 'Support Vector Machine',\n",
       "    'is_selected': False,\n",
       "    'linear_kernel': True,\n",
       "    'rep_kernel': True,\n",
       "    'polynomial_kernel': True,\n",
       "    'sigmoid_kernel': True,\n",
       "    'c_value': [566, 79],\n",
       "    'auto': True,\n",
       "    'scale': True,\n",
       "    'custom_gamma_values': True,\n",
       "    'tolerance': 7,\n",
       "    'max_iterations': 7},\n",
       "   'SGD': {'model_name': 'Stochastic Gradient Descent',\n",
       "    'is_selected': False,\n",
       "    'use_logistics': True,\n",
       "    'use_modified_hubber_loss': False,\n",
       "    'max_iterations': False,\n",
       "    'tolerance': 56,\n",
       "    'use_l1_regularization': 'on',\n",
       "    'use_l2_regularization': 'on',\n",
       "    'use_elastic_net_regularization': True,\n",
       "    'alpha_value': [79, 56],\n",
       "    'parallelism': 1},\n",
       "   'KNN': {'model_name': 'KNN',\n",
       "    'is_selected': False,\n",
       "    'k_value': [78],\n",
       "    'distance_weighting': True,\n",
       "    'neighbour_finding_algorithm': 'Automatic',\n",
       "    'random_state': 0,\n",
       "    'p_value': 0},\n",
       "   'extra_random_trees': {'model_name': 'Extra Random Trees',\n",
       "    'is_selected': False,\n",
       "    'num_of_trees': [45, 489],\n",
       "    'feature_sampling_statergy': 'Square root and Logarithm',\n",
       "    'max_depth': [12, 45],\n",
       "    'min_samples_per_leaf': [78, 56],\n",
       "    'parallelism': 3},\n",
       "   'neural_network': {'model_name': 'Neural Network',\n",
       "    'is_selected': False,\n",
       "    'hidden_layer_sizes': [67, 89],\n",
       "    'activation': '',\n",
       "    'alpha_value': 0,\n",
       "    'max_iterations': 0,\n",
       "    'convergence_tolerance': 0,\n",
       "    'early_stopping': True,\n",
       "    'solver': 'ADAM',\n",
       "    'shuffle_data': True,\n",
       "    'initial_learning_rate': 0,\n",
       "    'automatic_batching': True,\n",
       "    'beta_1': 0,\n",
       "    'beta_2': 0,\n",
       "    'epsilon': 0,\n",
       "    'power_t': 0,\n",
       "    'momentum': 0,\n",
       "    'use_nesterov_momentum': False}}}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cccf66b2-e9cb-40c3-aea4-604a87da5b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['session_name', 'session_description', 'design_state_data'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b32dfcc0-3133-4659-95f9-b8d900abc9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from striprtf.striprtf import rtf_to_text\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge, Lasso, ElasticNet, SGDClassifier, SGDRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "import xgboost as xgb\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1acb88b3-1703-4eef-881f-334cddaa6574",
   "metadata": {},
   "outputs": [],
   "source": [
    "class preprocess_pipeline():\n",
    "    def __init__(self, dic):\n",
    "        self.hashed = []\n",
    "        self.dic = dic\n",
    "        \n",
    "    def read_df(self):\n",
    "        file = dic[\"design_state_data\"][\"session_info\"][\"dataset\"]\n",
    "        df = pd.read_csv(file)\n",
    "        print(\"READ THE DATAFRAME\")\n",
    "        return df\n",
    "        \n",
    "    def data_selection(self):\n",
    "        self.df = self.read_df()\n",
    "        # target vars\n",
    "        pred = self.dic[\"design_state_data\"][\"target\"][\"prediction_type\"]\n",
    "        self.target = self.dic[\"design_state_data\"][\"target\"][\"target\"]\n",
    "        type_ = self.dic[\"design_state_data\"][\"target\"][\"type\"]\n",
    "        partition = self.dic[\"design_state_data\"][\"target\"][\"partitioning\"]\n",
    "\n",
    "        # train vars\n",
    "        train_columns = [x for x in self.df.columns if x != self.target]\n",
    "        train_size = self.dic[\"design_state_data\"][\"train\"][\"train_ratio\"]\n",
    "        \n",
    "        policy = self.dic[\"design_state_data\"][\"train\"][\"policy\"]\n",
    "        split1 = \"random\" in self.dic[\"design_state_data\"][\"train\"][\"policy\"].lower()\n",
    "        split2 = \"strat\" in self.dic[\"design_state_data\"][\"train\"][\"policy\"].lower()\n",
    "        randomness = self.dic[\"design_state_data\"][\"train\"][\"random_seed\"]\n",
    "        KFOLD = self.dic[\"design_state_data\"][\"train\"][\"k_fold\"]\n",
    "        \n",
    "        # train test split\n",
    "        if \"split\" in policy.lower():\n",
    "            X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "                                                                self.df[train_columns], \n",
    "                                                                self.df[self.target], \n",
    "                                                                train_size = train_size, \n",
    "                                                                shuffle = split1,\n",
    "                                                                #stratify = split2,\n",
    "                                                                random_state = randomness \n",
    "                                                                )\n",
    "            \n",
    "            X_train, X_test, Y_train, Y_test = self.feature_handling(X_train, X_test, Y_train, Y_test)\n",
    "            X_train, X_test = self.feature_generation(X_train, X_test)\n",
    "            print(\"SPLIT IMPUTATION COMPLETE\")\n",
    "            return \"normal_split\", [X_train, X_test, Y_train, Y_test]\n",
    "            \n",
    "        if KFOLD:\n",
    "            kf = KFold(n_splits=2, shuffle=True, random_state=42)\n",
    "            folds = []\n",
    "            # Generate splits\n",
    "            for train_idx, test_idx in kf.split(df):\n",
    "                X_train = df.loc[train_idx, train_columns]\n",
    "                X_test = df.loc[test_idx, train_columns]\n",
    "                Y_train = df.loc[train_idx, target]\n",
    "                Y_test = df.loc[test_idx, target]\n",
    "                \n",
    "                X_train, X_test, Y_train, Y_test = self.feature_handling(X_train, X_test, Y_train, Y_test)\n",
    "                X_train, X_test = self.feature_generation(X_train, X_test)\n",
    "                folds.append([X_train, X_test, Y_train, Y_test])\n",
    "                \n",
    "            print(\"KFOLDED IMPUTATION COMPLETE\")\n",
    "            return \"kfold\", folds\n",
    "    \n",
    "    def feature_handling(self, X_train, X_test, Y_train, Y_test):\n",
    "        # list features\n",
    "        features = list(self.dic[\"design_state_data\"][\"feature_handling\"].keys())\n",
    "        # grab the feature dictionary part\n",
    "        features_dic = self.dic[\"design_state_data\"][\"feature_handling\"]\n",
    "        #print(features_dic)\n",
    "        for feature in features:\n",
    "            if features_dic[feature][\"is_selected\"]:\n",
    "                if features_dic[feature][\"feature_variable_type\"].lower() == \"numerical\":\n",
    "                    imp_method = features_dic[feature][\"feature_details\"][\"impute_with\"].lower()\n",
    "                    if imp_method == \"custom\":\n",
    "                        imp_value = features_dic[feature][\"feature_details\"][\"impute_value\"]\n",
    "                        if feature == self.target:\n",
    "                            Y_train.fillna(imp_value,  inplace = True)\n",
    "                            Y_test.fillna(imp_value,  inplace = True) \n",
    "                        else:\n",
    "                            X_train.fillna({feature : imp_value}, inplace = True)\n",
    "                            X_test.fillna({feature : imp_value},  inplace = True)\n",
    "    \n",
    "                    else:\n",
    "                        if features_dic[feature][\"feature_variable_type\"].lower() == \"numerical\":\n",
    "                            if \"mean\" in imp_method or \"average\" in imp_method:\n",
    "                                strategy = \"mean\"\n",
    "                            elif \"median\" in imp_method:\n",
    "                                strategy = \"median\"\n",
    "                            elif \"mode\" in imp_method:\n",
    "                                strategy = \"mode\"\n",
    "                            si = SimpleImputer(strategy = strategy)\n",
    "    \n",
    "                            if feature == self.target:\n",
    "                                si.fit(Y_train)\n",
    "                                Y_train = si.transform(Y_train)\n",
    "                                Y_test = si.transform(Y_test)\n",
    "                            else:\n",
    "                                si.fit(X_train[feature].values.reshape(-1, 1))\n",
    "                                X_train[feature] = si.transform(X_train[feature].values.reshape(-1, 1)).ravel()\n",
    "                                X_test[feature] = si.transform(X_test[feature].values.reshape(-1, 1)).ravel()\n",
    "                                \n",
    "                else: # for text data\n",
    "                    self.hashed.append(feature)\n",
    "                    strategy = \"most_frequent\"\n",
    "    \n",
    "                    si = SimpleImputer(strategy = strategy)\n",
    "    \n",
    "                    if feature == self.target:\n",
    "                        si.fit(Y_train.values.reshape(-1, 1))\n",
    "                        Y_train = si.transform(Y_train.values.reshape(-1, 1)).ravel()\n",
    "                        Y_test = si.transform(Y_test.values.reshape(-1, 1)).ravel()\n",
    "                    else:\n",
    "                        si.fit(X_train[feature].values.reshape(-1, 1))\n",
    "                        X_train[feature] = si.transform(X_train[feature].values.reshape(-1, 1)).ravel()\n",
    "                        X_test[feature] = si.transform(X_test[feature].values.reshape(-1, 1)).ravel()\n",
    "                    \"\"\"\n",
    "                    not expecting the target variable to be hashed or tokenized so ignoring y_train, \n",
    "                    but if it is, we will use Label encoder instead\n",
    "                    \"\"\"\n",
    "                    if feature == self.target:\n",
    "                        e = LabelEncoder()\n",
    "                        e.fit(Y_train)\n",
    "                        Y_train = e.transform(Y_train)\n",
    "                        Y_test = e.transform(Y_test)\n",
    "                        \n",
    "                    else:\n",
    "                        # use hashing evctorizer\n",
    "                        hash_columns = features_dic[feature][\"feature_details\"][\"hash_columns\"]\n",
    "                        if hash_columns != 0: \n",
    "                            vectorizer = HashingVectorizer(n_features = hash_columns, stop_words = 'english', alternate_sign = False)\n",
    "            \n",
    "                            hashed_X_train = vectorizer.transform(X_train[feature].astype(str)).toarray()\n",
    "                            hashed_X_test = vectorizer.transform(X_test[feature].astype(str)).toarray()\n",
    "                            \n",
    "                            # vectorizer returns dense array create columns out of that \n",
    "                            hashed_X_train_df = pd.DataFrame(hashed_X_train, index=X_train.index,\n",
    "                                  columns=[f\"hashed_{feature}_{i}\" for i in range(hashed_X_train.shape[1])])\n",
    "                            hashed_X_test_df = pd.DataFrame(hashed_X_test, index=X_test.index,\n",
    "                                 columns=[f\"hashed_{feature}_{i}\" for i in range(hashed_X_test.shape[1])])\n",
    "\n",
    "                            # join\n",
    "                            X_train = pd.concat([X_train, hashed_X_train_df], axis=1)\n",
    "                            X_test = pd.concat([X_test, hashed_X_test_df], axis=1)\n",
    "\n",
    "                            # drop the string col\n",
    "                            X_train.drop(feature, axis = 1, inplace = True)\n",
    "                            X_test.drop(feature, axis = 1, inplace = True)\n",
    "                            \n",
    "                        else:\n",
    "                            e = LabelEncoder()\n",
    "                            e.fit(X_train[feature])\n",
    "                            X_train[feature] = e.transform(X_train[feature].values.reshape(-1, 1)).flatten()\n",
    "                            X_test[feature]= e.transform(X_test[feature].values.reshape(-1, 1)).flatten()\n",
    "                            \n",
    "        print(\"Feature handling complete\")\n",
    "        #display(X_test)\n",
    "        return X_train, X_test, Y_train, Y_test  \n",
    "\n",
    "    def interaction(self, interaction_list, interaction_type, X_train, X_test):\n",
    "        \"\"\"\n",
    "        handles interaction and takes care of hashed array interactions if any \n",
    "        \"\"\"\n",
    "        functiondic = {\n",
    "                       \"linear\" : lambda x, y : x + y,\n",
    "                       \"poly\" : lambda x, y : x / y, \n",
    "                       \"expl\" : lambda x, y : x / y\n",
    "                      }\n",
    "        \n",
    "        function = functiondic[interaction_type]\n",
    "        for x, y in interaction_list:\n",
    "            # skip when target is given for interaction, this causes dataleakage\n",
    "            if y == self.target: continue\n",
    "            if x == self.target: continue\n",
    "            \n",
    "            if x in self.hashed:\n",
    "                cols = [p for p in X_train.columns if f\"hashed_{x}\" in p]\n",
    "                for hashed_col in cols:\n",
    "                    X_train[f\"{hashed_col}_l_{y}\"] = function(X_train[hashed_col], X_train[y])\n",
    "                    X_test[f\"{hashed_col}_l_{y}\"] = function(X_test[hashed_col], X_test[y])\n",
    "\n",
    "            elif y in self.hashed:\n",
    "                cols = [p for p in X_train.columns if f\"hashed_{y}\" in p]\n",
    "                for hashed_col in cols:\n",
    "                    X_train[f\"{x}_l_{hashed_col}\"] = function(X_train[x], X_train[hashed_col])\n",
    "                    X_test[f\"{x}_l_{hashed_col}\"] = function(X_test[x], X_test[hashed_col])\n",
    "            \n",
    "            # not expecting both to be hashed would be worst case scenario\n",
    "            elif x in self.hashed and y in self.hashed:\n",
    "                colx = [p for p in X_train.columns if f\"hashed_{x}\" in p]\n",
    "                coly = [p for p in X_train.columns if f\"hashed_{y}\" in p]\n",
    "                \n",
    "                for hashed_x in colx:\n",
    "                    for hashed_y in coly:\n",
    "                        X_train[f\"{hashed_x}_l_{hashed_y}\"] = function(X_train[hashed_x], X_train[hashed_y])\n",
    "                        X_test[f\"{hashed_x}_l_{hashed_y}\"] = function(X_test[hashed_x], X_test[hashed_y])\n",
    "            else:\n",
    "                X_train[f\"{x}_l_{y}\"] = function(X_train[x], X_train[y])\n",
    "                X_test[f\"{x}_l_{y}\"] = function(X_test[x], X_test[y])\n",
    "        print(\"INTERACTION COMPLETE\")\n",
    "        return X_train, X_test\n",
    "\n",
    "\n",
    "    def feature_generation(self, X_train, X_test):\n",
    "        dic = self.dic[\"design_state_data\"][\"feature_generation\"]\n",
    "        \n",
    "        # add new linear features\n",
    "        X_train, X_test = self.interaction(dic[\"linear_interactions\"], \"linear\", X_train, X_test)\n",
    "            \n",
    "        # add polynomial features\n",
    "        polynomial_interactions = [x.split(\"/\") for x in dic[\"polynomial_interactions\"]]\n",
    "        X_train, X_test = self.interaction(polynomial_interactions, \"poly\", X_train, X_test)\n",
    "        \n",
    "        # add explicit pariwaise reln\n",
    "        explicit_pairwise_interactions = [x.split(\"/\") for x in dic[\"explicit_pairwise_interactions\"]]\n",
    "        X_train, X_test = self.interaction(explicit_pairwise_interactions, \"expl\", X_train, X_test)\n",
    "        print(\"FEATURE GENERATION COMPLETE\")\n",
    "        return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fb7f9787-a7a3-44cd-9585-c806463996e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "READ THE DATAFRAME\n",
      "Feature handling (45, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>hashed_species_0</th>\n",
       "      <th>hashed_species_1</th>\n",
       "      <th>hashed_species_2</th>\n",
       "      <th>hashed_species_3</th>\n",
       "      <th>hashed_species_4</th>\n",
       "      <th>hashed_species_5</th>\n",
       "      <th>hashed_species_6</th>\n",
       "      <th>hashed_species_7</th>\n",
       "      <th>hashed_species_8</th>\n",
       "      <th>hashed_species_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>7.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>7.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>6.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>7.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>6.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>7.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>7.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>7.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  hashed_species_0  \\\n",
       "105           7.6          3.0           6.6               0.0   \n",
       "106           4.9          2.5           4.5               0.0   \n",
       "107           7.3          2.9           6.3               0.0   \n",
       "108           6.7          2.5           5.8               0.0   \n",
       "109           7.2          3.6           6.1               0.0   \n",
       "110           6.5          3.2           5.1               0.0   \n",
       "111           6.4          2.7           5.3               0.0   \n",
       "112           6.8          3.0           5.5               0.0   \n",
       "113           5.7          2.5           5.0               0.0   \n",
       "114           5.8          2.8           5.1               0.0   \n",
       "115           6.4          3.2           5.3               0.0   \n",
       "116           6.5          3.0           5.5               0.0   \n",
       "117           7.7          3.8           6.7               0.0   \n",
       "118           7.7          2.6           6.9               0.0   \n",
       "119           6.0          2.2           5.0               0.0   \n",
       "120           6.9          3.2           5.7               0.0   \n",
       "121           5.6          2.8           4.9               0.0   \n",
       "122           7.7          2.8           6.7               0.0   \n",
       "123           6.3          2.7           4.9               0.0   \n",
       "124           6.7          3.3           5.7               0.0   \n",
       "125           7.2          3.2           6.0               0.0   \n",
       "126           6.2          2.8           4.8               0.0   \n",
       "127           6.1          3.0           4.9               0.0   \n",
       "128           6.4          2.8           5.6               0.0   \n",
       "129           7.2          3.0           5.8               0.0   \n",
       "130           7.4          2.8           6.1               0.0   \n",
       "131           7.9          3.8           6.4               0.0   \n",
       "132           6.4          2.8           5.6               0.0   \n",
       "133           6.3          2.8           5.1               0.0   \n",
       "134           6.1          2.6           5.6               0.0   \n",
       "135           7.7          3.0           6.1               0.0   \n",
       "136           6.3          3.4           5.6               0.0   \n",
       "137           6.4          3.1           5.5               0.0   \n",
       "138           6.0          3.0           4.8               0.0   \n",
       "139           6.9          3.1           5.4               0.0   \n",
       "140           6.7          3.1           5.6               0.0   \n",
       "141           6.9          3.1           5.1               0.0   \n",
       "142           5.8          2.7           5.1               0.0   \n",
       "143           6.8          3.2           5.9               0.0   \n",
       "144           6.7          3.3           5.7               0.0   \n",
       "145           6.7          3.0           5.2               0.0   \n",
       "146           6.3          2.5           5.0               0.0   \n",
       "147           6.5          3.0           5.2               0.0   \n",
       "148           6.2          3.4           5.4               0.0   \n",
       "149           5.9          3.0           5.1               0.0   \n",
       "\n",
       "     hashed_species_1  hashed_species_2  hashed_species_3  hashed_species_4  \\\n",
       "105          0.707107               0.0               0.0               0.0   \n",
       "106          0.707107               0.0               0.0               0.0   \n",
       "107          0.707107               0.0               0.0               0.0   \n",
       "108          0.707107               0.0               0.0               0.0   \n",
       "109          0.707107               0.0               0.0               0.0   \n",
       "110          0.707107               0.0               0.0               0.0   \n",
       "111          0.707107               0.0               0.0               0.0   \n",
       "112          0.707107               0.0               0.0               0.0   \n",
       "113          0.707107               0.0               0.0               0.0   \n",
       "114          0.707107               0.0               0.0               0.0   \n",
       "115          0.707107               0.0               0.0               0.0   \n",
       "116          0.707107               0.0               0.0               0.0   \n",
       "117          0.707107               0.0               0.0               0.0   \n",
       "118          0.707107               0.0               0.0               0.0   \n",
       "119          0.707107               0.0               0.0               0.0   \n",
       "120          0.707107               0.0               0.0               0.0   \n",
       "121          0.707107               0.0               0.0               0.0   \n",
       "122          0.707107               0.0               0.0               0.0   \n",
       "123          0.707107               0.0               0.0               0.0   \n",
       "124          0.707107               0.0               0.0               0.0   \n",
       "125          0.707107               0.0               0.0               0.0   \n",
       "126          0.707107               0.0               0.0               0.0   \n",
       "127          0.707107               0.0               0.0               0.0   \n",
       "128          0.707107               0.0               0.0               0.0   \n",
       "129          0.707107               0.0               0.0               0.0   \n",
       "130          0.707107               0.0               0.0               0.0   \n",
       "131          0.707107               0.0               0.0               0.0   \n",
       "132          0.707107               0.0               0.0               0.0   \n",
       "133          0.707107               0.0               0.0               0.0   \n",
       "134          0.707107               0.0               0.0               0.0   \n",
       "135          0.707107               0.0               0.0               0.0   \n",
       "136          0.707107               0.0               0.0               0.0   \n",
       "137          0.707107               0.0               0.0               0.0   \n",
       "138          0.707107               0.0               0.0               0.0   \n",
       "139          0.707107               0.0               0.0               0.0   \n",
       "140          0.707107               0.0               0.0               0.0   \n",
       "141          0.707107               0.0               0.0               0.0   \n",
       "142          0.707107               0.0               0.0               0.0   \n",
       "143          0.707107               0.0               0.0               0.0   \n",
       "144          0.707107               0.0               0.0               0.0   \n",
       "145          0.707107               0.0               0.0               0.0   \n",
       "146          0.707107               0.0               0.0               0.0   \n",
       "147          0.707107               0.0               0.0               0.0   \n",
       "148          0.707107               0.0               0.0               0.0   \n",
       "149          0.707107               0.0               0.0               0.0   \n",
       "\n",
       "     hashed_species_5  hashed_species_6  hashed_species_7  hashed_species_8  \\\n",
       "105               0.0          0.707107               0.0               0.0   \n",
       "106               0.0          0.707107               0.0               0.0   \n",
       "107               0.0          0.707107               0.0               0.0   \n",
       "108               0.0          0.707107               0.0               0.0   \n",
       "109               0.0          0.707107               0.0               0.0   \n",
       "110               0.0          0.707107               0.0               0.0   \n",
       "111               0.0          0.707107               0.0               0.0   \n",
       "112               0.0          0.707107               0.0               0.0   \n",
       "113               0.0          0.707107               0.0               0.0   \n",
       "114               0.0          0.707107               0.0               0.0   \n",
       "115               0.0          0.707107               0.0               0.0   \n",
       "116               0.0          0.707107               0.0               0.0   \n",
       "117               0.0          0.707107               0.0               0.0   \n",
       "118               0.0          0.707107               0.0               0.0   \n",
       "119               0.0          0.707107               0.0               0.0   \n",
       "120               0.0          0.707107               0.0               0.0   \n",
       "121               0.0          0.707107               0.0               0.0   \n",
       "122               0.0          0.707107               0.0               0.0   \n",
       "123               0.0          0.707107               0.0               0.0   \n",
       "124               0.0          0.707107               0.0               0.0   \n",
       "125               0.0          0.707107               0.0               0.0   \n",
       "126               0.0          0.707107               0.0               0.0   \n",
       "127               0.0          0.707107               0.0               0.0   \n",
       "128               0.0          0.707107               0.0               0.0   \n",
       "129               0.0          0.707107               0.0               0.0   \n",
       "130               0.0          0.707107               0.0               0.0   \n",
       "131               0.0          0.707107               0.0               0.0   \n",
       "132               0.0          0.707107               0.0               0.0   \n",
       "133               0.0          0.707107               0.0               0.0   \n",
       "134               0.0          0.707107               0.0               0.0   \n",
       "135               0.0          0.707107               0.0               0.0   \n",
       "136               0.0          0.707107               0.0               0.0   \n",
       "137               0.0          0.707107               0.0               0.0   \n",
       "138               0.0          0.707107               0.0               0.0   \n",
       "139               0.0          0.707107               0.0               0.0   \n",
       "140               0.0          0.707107               0.0               0.0   \n",
       "141               0.0          0.707107               0.0               0.0   \n",
       "142               0.0          0.707107               0.0               0.0   \n",
       "143               0.0          0.707107               0.0               0.0   \n",
       "144               0.0          0.707107               0.0               0.0   \n",
       "145               0.0          0.707107               0.0               0.0   \n",
       "146               0.0          0.707107               0.0               0.0   \n",
       "147               0.0          0.707107               0.0               0.0   \n",
       "148               0.0          0.707107               0.0               0.0   \n",
       "149               0.0          0.707107               0.0               0.0   \n",
       "\n",
       "     hashed_species_9  \n",
       "105               0.0  \n",
       "106               0.0  \n",
       "107               0.0  \n",
       "108               0.0  \n",
       "109               0.0  \n",
       "110               0.0  \n",
       "111               0.0  \n",
       "112               0.0  \n",
       "113               0.0  \n",
       "114               0.0  \n",
       "115               0.0  \n",
       "116               0.0  \n",
       "117               0.0  \n",
       "118               0.0  \n",
       "119               0.0  \n",
       "120               0.0  \n",
       "121               0.0  \n",
       "122               0.0  \n",
       "123               0.0  \n",
       "124               0.0  \n",
       "125               0.0  \n",
       "126               0.0  \n",
       "127               0.0  \n",
       "128               0.0  \n",
       "129               0.0  \n",
       "130               0.0  \n",
       "131               0.0  \n",
       "132               0.0  \n",
       "133               0.0  \n",
       "134               0.0  \n",
       "135               0.0  \n",
       "136               0.0  \n",
       "137               0.0  \n",
       "138               0.0  \n",
       "139               0.0  \n",
       "140               0.0  \n",
       "141               0.0  \n",
       "142               0.0  \n",
       "143               0.0  \n",
       "144               0.0  \n",
       "145               0.0  \n",
       "146               0.0  \n",
       "147               0.0  \n",
       "148               0.0  \n",
       "149               0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interaction (45, 14)\n",
      "interaction (45, 14)\n",
      "interaction (45, 15)\n",
      "generation (45, 15)\n",
      "SPLIT IMPUTATION COMPLETE\n"
     ]
    }
   ],
   "source": [
    "with open(r\"C:\\Users\\91962\\Downloads\\DS_Assignment - internship\\Screening Test - DS\\algoparams_from_ui.json.rtf\", \"r\", encoding=\"utf-8\") as file:\n",
    "    rtf_content = file.read()\n",
    "    \n",
    "text = rtf_to_text(rtf_content)\n",
    "dic = json.loads(text)\n",
    "\n",
    "k = preprocess_pipeline(dic)\n",
    "u = k.data_selection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d2b2d27d-6a52-425b-b813-955040100317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 15)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u[1][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5cc6a32c-cf6b-42b2-8954-03ff00711b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class feature_reduction_pipeline:\n",
    "    def __init__(self, dic, X_train, X_test, target):\n",
    "        self.dic = dic\n",
    "        self.method = dic[\"feature_reduction_method\"].lower()\n",
    "        self.X_train = X_train.copy()\n",
    "        self.X_test = X_test.copy()\n",
    "        self.target = target\n",
    "    \n",
    "    def execute(self):\n",
    "        if \"correlation\" in self.method:\n",
    "            return self.correlation(0.4)\n",
    "            \n",
    "        elif \"principal\" in self.method:\n",
    "            return self.pca(self.dic[self.method][\"num_features_to_keep\"])\n",
    "            \n",
    "        elif \"tree\" in self.method:\n",
    "            depth = self.dic[self.method][\"depth_of_trees\"]\n",
    "            numt = self.dic[self.method][\"num_of_trees\"]\n",
    "            n = self.dic[self.method][\"num_features_to_keep\"]\n",
    "            return self.tree(num_features_to_keep=n, num_trees=numt, depth=depth)\n",
    "        \n",
    "        else:\n",
    "            return self.X_train, self.X_test\n",
    "            \n",
    "    def correlation(self, threshold=0.4):\n",
    "        combined = pd.concat([self.X_train, self.X_test])\n",
    "        corr_matrix = combined.corr().abs()\n",
    "         # Keeps the values where the condition is True and replaces everything else with NaN.                  \n",
    "        \"\"\"                 |    # makes it triangle # creates a corelation matrix like array with ones\n",
    "                            |           |                |\n",
    "                            v           v                v                 \"\"\"\n",
    "        upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "        to_drop = []\n",
    "        \n",
    "        for column in upper.columns:\n",
    "            if any(upper[column] >= threshold):\n",
    "                to_drop.append(column)\n",
    "                \n",
    "        keep = [column for column in corr_matrix.columns if column not in to_drop]\n",
    "        \n",
    "        return self.X_train[keep], self.X_test[keep]\n",
    "    \n",
    "    def pca(self, n=3):\n",
    "        combined = pd.concat([self.X_train, self.X_test])\n",
    "        \n",
    "        pca = PCA(n_components=n)\n",
    "        pca.fit(combined)\n",
    "        \n",
    "        train_transformed = pca.transform(self.X_train)\n",
    "        test_transformed = pca.transform(self.X_test)\n",
    "        \n",
    "        cols = [f'PC{i+1}' for i in range(n)]\n",
    "        train_pca = pd.DataFrame(train_transformed, index = self.X_train.index, columns = cols)\n",
    "        test_pca = pd.DataFrame(test_transformed, index = self.X_test.index, columns = cols)\n",
    "        \n",
    "        return train_pca, test_pca\n",
    "    \n",
    "    def tree(self, num_features_to_keep=10, num_trees=100, depth=6):\n",
    "        \n",
    "        if self.target in self.X_train.columns:\n",
    "            X = self.X_train.drop(columns=[self.target])\n",
    "            y = self.X_train[self.target]\n",
    "        else:\n",
    "            X = self.X_train\n",
    "        \n",
    "        rf = RandomForestClassifier(n_estimators = num_trees, max_depth = depth)\n",
    "        rf.fit(X, y)\n",
    "        \n",
    "        # feature importances\n",
    "        importances = rf.feature_importances_\n",
    "        feature_names = X.columns.tolist()\n",
    "        \n",
    "        # sort features on importance\n",
    "        features_with_importance = list(zip(feature_names, importances))\n",
    "        sorted_features = sorted(features_with_importance, key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # select top N features\n",
    "        selected_features = [f[0] for f in sorted_features[:num_features_to_keep]]\n",
    "        \n",
    "        X_train_reduced = self.X_train[selected_features]\n",
    "        X_test_reduced = self.X_test[selected_features]\n",
    "        \n",
    "        return X_train_reduced, X_test_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9da9ba2e-cb84-406b-b701-c60426fb7f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_dic = dic[\"design_state_data\"][\"feature_reduction\"]\n",
    "target = dic[\"design_state_data\"][\"target\"][\"target\"]\n",
    "dimred = feature_reduction_pipeline(local_dic, u[1][0], u[1][1], target)\n",
    "k = dimred.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9e9ac08d-8a97-487b-a11f-4892b69eb458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>hashed_species_0</th>\n",
       "      <th>hashed_species_2</th>\n",
       "      <th>hashed_species_3</th>\n",
       "      <th>hashed_species_4</th>\n",
       "      <th>hashed_species_5</th>\n",
       "      <th>hashed_species_6</th>\n",
       "      <th>hashed_species_8</th>\n",
       "      <th>hashed_species_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>7.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  hashed_species_0  hashed_species_2  \\\n",
       "0             5.1          3.5               0.0               0.0   \n",
       "1             4.9          3.0               0.0               0.0   \n",
       "2             4.7          3.2               0.0               0.0   \n",
       "3             4.6          3.1               0.0               0.0   \n",
       "4             5.0          3.6               0.0               0.0   \n",
       "..            ...          ...               ...               ...   \n",
       "100           6.3          3.3               0.0               0.0   \n",
       "101           5.8          2.7               0.0               0.0   \n",
       "102           7.1          3.0               0.0               0.0   \n",
       "103           6.3          2.9               0.0               0.0   \n",
       "104           6.5          3.0               0.0               0.0   \n",
       "\n",
       "     hashed_species_3  hashed_species_4  hashed_species_5  hashed_species_6  \\\n",
       "0                 0.0               0.0               0.0          0.707107   \n",
       "1                 0.0               0.0               0.0          0.707107   \n",
       "2                 0.0               0.0               0.0          0.707107   \n",
       "3                 0.0               0.0               0.0          0.707107   \n",
       "4                 0.0               0.0               0.0          0.707107   \n",
       "..                ...               ...               ...               ...   \n",
       "100               0.0               0.0               0.0          0.707107   \n",
       "101               0.0               0.0               0.0          0.707107   \n",
       "102               0.0               0.0               0.0          0.707107   \n",
       "103               0.0               0.0               0.0          0.707107   \n",
       "104               0.0               0.0               0.0          0.707107   \n",
       "\n",
       "     hashed_species_8  hashed_species_9  \n",
       "0                 0.0               0.0  \n",
       "1                 0.0               0.0  \n",
       "2                 0.0               0.0  \n",
       "3                 0.0               0.0  \n",
       "4                 0.0               0.0  \n",
       "..                ...               ...  \n",
       "100               0.0               0.0  \n",
       "101               0.0               0.0  \n",
       "102               0.0               0.0  \n",
       "103               0.0               0.0  \n",
       "104               0.0               0.0  \n",
       "\n",
       "[105 rows x 10 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8b320735-6e26-4c26-8bd7-a2db22b19669",
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_pipeline:\n",
    "    def __init__(self, dic):\n",
    "        self.dic = dic\n",
    "        # get design state data part\n",
    "        self.design_data = self.dic[\"design_state_data\"]\n",
    "        # get pred type\n",
    "        self.prediction_type = self.design_data[\"target\"][\"prediction_type\"]\n",
    "        # get algo\n",
    "        self.selected_algorithms = self._get_selected_algorithms()\n",
    "        self.best_model = None\n",
    "        self.best_score = float('-inf') if self.prediction_type == \"Classification\" else float('inf')\n",
    "        self.best_params = None\n",
    "        \n",
    "    def _get_selected_algorithms(self):\n",
    "        selected = []\n",
    "        for algo_name, algo_config in self.design_data[\"algorithms\"].items():\n",
    "            if algo_config[\"is_selected\"]:\n",
    "                selected.append((algo_name, algo_config))\n",
    "                #print(algo_name, algo_config)\n",
    "        return selected\n",
    "        \n",
    "    def apply_sample_weights(self, X_train, Y_train):\n",
    "        weight_strategy = self.design_data[\"weighting_stratergy\"]\n",
    "        if weight_strategy[\"weighting_stratergy_method\"] == \"Sample weights\":\n",
    "            weight_var = weight_strategy[\"weighting_stratergy_weight_variable\"]\n",
    "            \n",
    "            if weight_var in X_train.columns:\n",
    "                sample_weights = X_train[weight_var].values\n",
    "                # remove weight variable from features\n",
    "                X_train = X_train.drop(columns=[weight_var])\n",
    "                return X_train, Y_train, sample_weights\n",
    "                \n",
    "        return X_train, Y_train, None\n",
    "    \n",
    "    def create_grid_params(self, algo_name, algo_config):\n",
    "        if algo_name == \"RandomForestClassifier\" or algo_name == \"RandomForestRegressor\":\n",
    "            return  {\n",
    "                'n_estimators': list(range(algo_config[\"min_trees\"], algo_config[\"max_trees\"] + 1, 5)),\n",
    "                'max_depth': list(range(algo_config[\"min_depth\"], algo_config[\"max_depth\"] + 1, 5)),\n",
    "                'min_samples_leaf': list(range(algo_config[\"min_samples_per_leaf_min_value\"], \n",
    "                                           algo_config[\"min_samples_per_leaf_max_value\"] + 1, 5))\n",
    "            }\n",
    "            \n",
    "        elif algo_name == \"GBTClassifier\" or algo_name == \"GBTRegressor\":\n",
    "            return {\n",
    "                'n_estimators': algo_config[\"num_of_BoostingStages\"],\n",
    "                'max_depth': list(range(algo_config[\"min_depth\"], algo_config[\"max_depth\"] + 1)),\n",
    "                'learning_rate': [algo_config[\"min_stepsize\"] + i * 0.05 for i in range(\n",
    "                    int((algo_config[\"max_stepsize\"] - algo_config[\"min_stepsize\"]) / 0.05) + 1)],\n",
    "                'subsample': [algo_config[\"min_subsample\"] + i * 0.1 for i in range(\n",
    "                    int((algo_config[\"max_subsample\"] - algo_config[\"min_subsample\"]) / 0.1) + 1)]\n",
    "            }\n",
    "            \n",
    "        elif algo_name == \"LinearRegression\" or algo_name == \"LogisticRegression\":\n",
    "            return {\n",
    "                'max_iter': list(range(algo_config[\"min_iter\"], algo_config[\"max_iter\"] + 10, 10)),\n",
    "                'tol': [0.0001, 0.001, 0.01],\n",
    "                'C': [1.0 / (algo_config[\"min_regparam\"] + i * 0.1) for i in range(\n",
    "                    int((algo_config[\"max_regparam\"] - algo_config[\"min_regparam\"]) / 0.1) + 1)],  \n",
    "                'l1_ratio': [algo_config[\"min_elasticnet\"] + i * 0.1 for i in range(\n",
    "                    int((algo_config[\"max_elasticnet\"] - algo_config[\"min_elasticnet\"]) / 0.1) + 1)] if \"elasticnet\" in algo_config else [0.5]\n",
    "            }\n",
    "            \n",
    "        elif algo_name == \"RidgeRegression\":\n",
    "            return {\n",
    "                'max_iter': list(range(algo_config[\"min_iter\"], algo_config[\"max_iter\"] + 10, 10)),\n",
    "                'alpha': [algo_config[\"min_regparam\"] + i * 0.1 for i in range(\n",
    "                    int((algo_config[\"max_regparam\"] - algo_config[\"min_regparam\"]) / 0.1) + 1)]\n",
    "            }\n",
    "            \n",
    "        elif algo_name == \"LassoRegression\":\n",
    "            return {\n",
    "                'max_iter': list(range(algo_config[\"min_iter\"], algo_config[\"max_iter\"] + 10, 10)),\n",
    "                'alpha': [algo_config[\"min_regparam\"] + i * 0.1 for i in range(\n",
    "                    int((algo_config[\"max_regparam\"] - algo_config[\"min_regparam\"]) / 0.1) + 1)]\n",
    "            }\n",
    "            \n",
    "        elif algo_name == \"ElasticNetRegression\":\n",
    "            return {\n",
    "                'max_iter': list(range(algo_config[\"min_iter\"], algo_config[\"max_iter\"] + 10, 10)),\n",
    "                'alpha': [algo_config[\"min_regparam\"] + i * 0.1 for i in range(\n",
    "                    int((algo_config[\"max_regparam\"] - algo_config[\"min_regparam\"]) / 0.1) + 1)],\n",
    "                'l1_ratio': [algo_config[\"min_elasticnet\"] + i * 0.1 for i in range(\n",
    "                    int((algo_config[\"max_elasticnet\"] - algo_config[\"min_elasticnet\"]) / 0.1) + 1)]\n",
    "            }\n",
    "            \n",
    "        elif algo_name == \"xg_boost\":\n",
    "            return {\n",
    "                'max_depth': list(range(algo_config[\"max_depth_of_tree\"][0], algo_config[\"max_depth_of_tree\"][1] + 1, 10)),\n",
    "                'learning_rate': algo_config[\"learningRate\"],\n",
    "                'n_estimators': [10, 20, 50, 100],\n",
    "                'gamma': algo_config[\"gamma\"] if \"gamma\" in algo_config else [0],\n",
    "                'reg_alpha': algo_config[\"l1_regularization\"] if \"l1_regularization\" in algo_config else [0],\n",
    "                'reg_lambda': algo_config[\"l2_regularization\"] if \"l2_regularization\" in algo_config else [1],\n",
    "                'subsample': algo_config[\"sub_sample\"] if \"sub_sample\" in algo_config else [0.8],\n",
    "                'colsample_bytree': algo_config[\"col_sample_by_tree\"] if \"col_sample_by_tree\" in algo_config else [0.8]\n",
    "            }\n",
    "            \n",
    "        elif algo_name == \"DecisionTreeRegressor\" or algo_name == \"DecisionTreeClassifier\":\n",
    "            return {\n",
    "                'max_depth': list(range(algo_config[\"min_depth\"], algo_config[\"max_depth\"] + 1)),\n",
    "                'min_samples_leaf': algo_config[\"min_samples_per_leaf\"],\n",
    "                'criterion': ['gini' if algo_config.get(\"use_gini\", False) else 'entropy'] if algo_name.endswith(\"Classifier\") else ['squared_error', 'friedman_mse']\n",
    "            }\n",
    "            \n",
    "        elif algo_name == \"SVM\":\n",
    "            kernels = []\n",
    "            if algo_config.get(\"linear_kernel\", False): kernels.append('linear')\n",
    "            if algo_config.get(\"polynomial_kernel\", False): kernels.append('poly')\n",
    "            if algo_config.get(\"sigmoid_kernel\", False): kernels.append('sigmoid')\n",
    "            if algo_config.get(\"rep_kernel\", False): kernels.append('rbf')\n",
    "            \n",
    "            gamma_values = ['auto', 'scale']\n",
    "            if algo_config.get(\"custom_gamma_values\", False):\n",
    "                gamma_values.extend([0.001, 0.01, 0.1, 1])\n",
    "                \n",
    "            return {\n",
    "                'C': algo_config[\"c_value\"],\n",
    "                'kernel': kernels if kernels else ['rbf'],\n",
    "                'gamma': gamma_values,\n",
    "                'tol': [algo_config[\"tolerance\"] * 0.001],\n",
    "                'max_iter': [algo_config[\"max_iterations\"] * 100]\n",
    "            }\n",
    "            \n",
    "        elif algo_name == \"SGD\":\n",
    "            losses = []\n",
    "            if algo_config.get(\"use_logistics\", False): losses.append('log_loss')\n",
    "            if algo_config.get(\"use_modified_hubber_loss\", False): losses.append('modified_huber')\n",
    "            regularizations = []\n",
    "            if algo_config.get(\"use_l1_regularization\") == \"on\": regularizations.append('l1')\n",
    "            if algo_config.get(\"use_l2_regularization\") == \"on\": regularizations.append('l2')\n",
    "            if algo_config.get(\"use_elastic_net_regularization\", False): regularizations.append('elasticnet')\n",
    "            \n",
    "            return {\n",
    "                'loss': losses if losses else ['log_loss'],\n",
    "                'penalty': regularizations if regularizations else ['l2'],\n",
    "                'alpha': algo_config[\"alpha_value\"],\n",
    "                'max_iter': [algo_config[\"max_iterations\"] * 10] if \"max_iterations\" in algo_config else [1000],\n",
    "                'tol': [algo_config[\"tolerance\"] * 0.0001] if \"tolerance\" in algo_config else [0.0001]\n",
    "            }\n",
    "            \n",
    "        elif algo_name == \"KNN\":\n",
    "            return {\n",
    "                'n_neighbors': algo_config[\"k_value\"],\n",
    "                'weights': ['uniform', 'distance'] if algo_config.get(\"distance_weighting\", False) else ['uniform'],\n",
    "                'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'] if algo_config.get(\"neighbour_finding_algorithm\") == \"Automatic\" else [algo_config.get(\"neighbour_finding_algorithm\").lower()],\n",
    "                'p': [algo_config[\"p_value\"]] if \"p_value\" in algo_config and algo_config[\"p_value\"] > 0 else [2]\n",
    "            }\n",
    "            \n",
    "        elif algo_name == \"extra_random_trees\":\n",
    "            return {\n",
    "                'n_estimators': [x for x in range(algo_config[\"num_of_trees\"][0], algo_config[\"num_of_trees\"][1] + 10, 10)],\n",
    "                'max_depth': [x for x in range(algo_config[\"max_depth\"][0], algo_config[\"max_depth\"][1] + 1)],\n",
    "                'min_samples_leaf': algo_config[\"min_samples_per_leaf\"],\n",
    "                'n_jobs': [algo_config[\"parallelism\"]] if \"parallelism\" in algo_config else [1]\n",
    "            }\n",
    "            \n",
    "        elif algo_name == \"neural_network\":\n",
    "            return {\n",
    "                'hidden_layer_sizes': [(algo_config[\"hidden_layer_sizes\"][0],), (algo_config[\"hidden_layer_sizes\"][1],)],\n",
    "                'activation': ['relu', 'tanh', 'logistic'] if not algo_config.get(\"activation\") else [algo_config.get(\"activation\")],\n",
    "                'alpha': [algo_config[\"alpha_value\"]] if \"alpha_value\" in algo_config else [0.0001],\n",
    "                'max_iter': [algo_config[\"max_iterations\"]] if \"max_iterations\" in algo_config else [200],\n",
    "                'tol': [algo_config[\"convergence_tolerance\"]] if \"convergence_tolerance\" in algo_config else [0.0001],\n",
    "                'learning_rate_init': [algo_config[\"initial_learning_rate\"]] if \"initial_learning_rate\" in algo_config else [0.001],\n",
    "                'solver': [algo_config[\"solver\"]] if \"solver\" in algo_config else ['adam'],\n",
    "                'batch_size': ['auto'] if algo_config.get(\"automatic_batching\", True) else [200],\n",
    "                'momentum': [algo_config[\"momentum\"]] if \"momentum\" in algo_config else [0.9],\n",
    "                'nesterovs_momentum': [algo_config[\"use_nesterov_momentum\"]] if \"use_nesterov_momentum\" in algo_config else [True]\n",
    "            }\n",
    "            \n",
    "        else:\n",
    "            return {}\n",
    "    \n",
    "    def get_model(self, algo_name):\n",
    "\n",
    "        if self.prediction_type.lower() == \"classification\":\n",
    "            models = {\n",
    "                \"RandomForestClassifier\": RandomForestClassifier(),\n",
    "                \"GBTClassifier\": GradientBoostingClassifier(),\n",
    "                \"LogisticRegression\": LogisticRegression(solver='saga'),\n",
    "                \"xg_boost\": xgb.XGBClassifier(),\n",
    "                \"DecisionTreeClassifier\": DecisionTreeClassifier(),\n",
    "                \"SVM\": SVC(probability=True),\n",
    "                \"SGD\": SGDClassifier(),\n",
    "                \"KNN\": KNeighborsClassifier(),\n",
    "                \"extra_random_trees\": RandomForestClassifier(bootstrap=False, random_state=42),\n",
    "                \"neural_network\": MLPClassifier()\n",
    "            }\n",
    "            \n",
    "        else:\n",
    "            models = {\n",
    "                \"RandomForestRegressor\": RandomForestRegressor(),\n",
    "                \"GBTRegressor\": GradientBoostingRegressor(),\n",
    "                \"xg_boost\": xgb.XGBRegressor(),\n",
    "                \"DecisionTreeRegressor\": DecisionTreeRegressor(),\n",
    "                \"SGD\": SGDRegressor(),\n",
    "                \"KNN\": KNeighborsRegressor(),\n",
    "                \"extra_random_trees\": RandomForestRegressor(bootstrap=False, random_state=42),\n",
    "                \"neural_network\": MLPRegressor()\n",
    "            }\n",
    "\n",
    "        return models[algo_name]\n",
    "\n",
    "\n",
    "    def train_and_evaluate(self, X_train, X_test, Y_train, Y_test):\n",
    "\n",
    "        results = []\n",
    "        \n",
    "        X_train, Y_train, sample_weights = self.apply_sample_weights(X_train, Y_train)\n",
    "        #print(self.selected_algorithms)\n",
    "        \n",
    "        for algo_name, algo_config in self.selected_algorithms:\n",
    "            print(f\"Training {algo_name}...\")\n",
    "            model_base = self.get_model(algo_name)\n",
    "            print(model_base)\n",
    "            params = self.create_grid_params(algo_name, algo_config)\n",
    "            \n",
    "            cv = KFold(n_splits=self.design_data[\"hyperparameters\"].get(\"num_of_folds\", 3), \n",
    "                       shuffle=self.design_data[\"hyperparameters\"].get(\"shuffle_grid\", True),\n",
    "                       random_state=self.design_data[\"hyperparameters\"].get(\"random_state\", 42))\n",
    "            \n",
    "            if self.prediction_type.lower() == \"classification\":\n",
    "                scoring = 'accuracy'\n",
    "            else:\n",
    "                scoring = 'neg_mean_squared_error'\n",
    "            \n",
    "            grid_search = GridSearchCV(\n",
    "                estimator=model_base,\n",
    "                param_grid=params,\n",
    "                scoring=scoring,\n",
    "                cv=cv,\n",
    "                n_jobs=self.design_data[\"hyperparameters\"].get(\"parallelism\", -1),\n",
    "                verbose=1\n",
    "            )\n",
    "            # to get the process time\n",
    "            start_time = time.time()\n",
    "            \n",
    "            if sample_weights is not None:\n",
    "                grid_search.fit(X_train, Y_train, sample_weight=sample_weights)\n",
    "            else:\n",
    "                grid_search.fit(X_train, Y_train)\n",
    "                \n",
    "            train_time = time.time() - start_time\n",
    "            \n",
    "            best_model = grid_search.best_estimator_\n",
    "            best_params = grid_search.best_params_\n",
    "            \n",
    "            y_pred = best_model.predict(X_test)\n",
    "            print(Y_test.shape, y_pred.shape)\n",
    "            metrics = self.calculate_metrics(Y_test, y_pred)\n",
    "            metrics['algorithm'] = algo_name\n",
    "            metrics['train_time'] = train_time\n",
    "            metrics['best_params'] = best_params\n",
    "            \n",
    "            results.append((algo_name, best_model, metrics))\n",
    "            \n",
    "            # check type of model to be used get best one\n",
    "            if self.prediction_type.lower() == \"classification\":\n",
    "                if metrics.get('accuracy', 0) > self.best_score:\n",
    "                    self.best_score = metrics.get('accuracy', 0)\n",
    "                    self.best_model = best_model\n",
    "                    self.best_params = best_params\n",
    "            else:\n",
    "                if metrics.get('mse', float('inf')) < self.best_score:\n",
    "                    self.best_score = metrics.get('mse', float('inf'))\n",
    "                    self.best_model = best_model\n",
    "                    self.best_params = best_params\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def calculate_metrics(self, y_true, y_pred):\n",
    "        metrics = {}\n",
    "        \n",
    "        if self.prediction_type.lower() == \"classification\":\n",
    "            metrics['accuracy'] = accuracy_score(y_true, y_pred)\n",
    "            metrics['precision'] = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "            metrics['recall'] = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "            metrics['f1'] = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "            \n",
    "            try:\n",
    "                if len(np.unique(y_true)) == 2:\n",
    "                    metrics['auc'] = roc_auc_score(y_true, y_pred)\n",
    "            except:\n",
    "                metrics['auc'] = 0\n",
    "        else:\n",
    "            metrics['mse'] = mean_squared_error(y_true, y_pred)\n",
    "            metrics['rmse'] = np.sqrt(metrics['mse'])\n",
    "            metrics['r2'] = r2_score(y_true, y_pred)\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def predict(self, X_new):\n",
    "        # predcit from the best\n",
    "        return self.best_model.predict(X_new)\n",
    "    \n",
    "    def get_feature_importance(self):\n",
    "        if self.best_model is None:\n",
    "            return None\n",
    "        \n",
    "        if hasattr(self.best_model, 'feature_importances_'):\n",
    "            return self.best_model.feature_importances_\n",
    "        elif hasattr(self.best_model, 'coef_'):\n",
    "            return self.best_model.coef_\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "def run_pipeline(X_train, X_test, Y_train, Y_test, dic):\n",
    "    model_pipe = model_pipeline(dic)\n",
    "    results = model_pipe.train_and_evaluate(X_train, X_test, Y_train, Y_test)\n",
    "    \n",
    "    print(\"\\n----- Results Summary -----\")\n",
    "    for algo_name, model, metrics in results:\n",
    "        print(f\"\\nAlgorithm: {algo_name}\")\n",
    "        for metric_name, metric_value in metrics.items():\n",
    "            if metric_name not in ['algorithm', 'train_time', 'best_params']:\n",
    "                print(f\"  {metric_name}: {metric_value}\")\n",
    "        print(f\"  Training time: {metrics['train_time']:.2f} seconds\")\n",
    "    \n",
    "    print(f\"\\nBest Model: {type(model_pipe.best_model).__name__}\")\n",
    "    print(f\"Best Parameters: {model_pipe.best_params}\")\n",
    "    \n",
    "    if model_pipe.prediction_type.lower() == \"classification\":\n",
    "        print(f\"Best Accuracy: {model_pipe.best_score:.4f}\")\n",
    "    else:\n",
    "        print(f\"Best MSE: {model_pipe.best_score:.4f}\")\n",
    "    return model_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8a2cda16-98bf-48e4-bc66-bb02b7c20620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((90, 10), (45,))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a32bb7bd-57df-42ba-9aa6-8f2565fa5434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RandomForestRegressor...\n",
      "RandomForestRegressor()\n",
      "Fitting 6 folds for each of 12 candidates, totalling 72 fits\n",
      "(45,) (45,)\n",
      "\n",
      "----- Results Summary -----\n",
      "\n",
      "Algorithm: RandomForestRegressor\n",
      "  mse: 0.367543522456339\n",
      "  rmse: 0.6062536783033476\n",
      "  r2: -3.914007876496017\n",
      "  Training time: 1.78 seconds\n",
      "\n",
      "Best Model: RandomForestRegressor\n",
      "Best Parameters: {'max_depth': 20, 'min_samples_leaf': 5, 'n_estimators': 20}\n",
      "Best MSE: 0.3675\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.model_pipeline at 0x210832ba910>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test = k  \n",
    "Y_train = u[1][2]  \n",
    "Y_test = u[1][3]   \n",
    "\n",
    "run_pipeline(X_train, X_test, Y_train, Y_test, dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dad95b3-e725-4ba9-b322-2329bcc00749",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdd5969-9beb-4946-b39e-cefefa081217",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dbce0b-30d6-49c0-a8ec-aefa0ffa2112",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b94aec-4db5-4501-bce9-3c7a3d2eb8aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-cuda",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
